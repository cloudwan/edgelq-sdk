syntax = "proto3";

package ntt.ai.v1;

import "edgelq-sdk/ai/proto/v1/common.proto";
import "google/protobuf/duration.proto";
import "google/protobuf/wrappers.proto";

option go_package = "github.com/cloudwan/edgelq-sdk/ai/client/v1/responses;responses_client";
option java_multiple_files = false;
option java_outer_classname = "ResponsesCustomProto";
option java_package = "com.ntt.ai.pb.v1";

// Client → Server messages
message CreateResponseRequest { CreateRequest create_request = 1; }

message CreateRequest {
  // The conversation
  repeated Message messages = 1;

  // Model selection
  string model = 2;

  // Client explicitly declares its tools
  repeated ToolDefinition client_tools = 4;

  // Server-side tool configuration - choose one:
  oneof server_tools_config {
    // Option 1: Use a pre-configured capability template
    string capability_template = 5;

    // Option 2: Directly specify connectors
    ConnectorsList connectors = 6;
  }

  // Standard LLM params
  int32 max_tokens = 7;

  float temperature = 8;

  // Optional: reference to existing conversation
  string conversation_name = 9;

  // Scope for authorization and tracking. Can be project, organization, or
  // empty. Format: "projects/{project}", "organizations/{org}", or ""
  string parent = 12;

  // Requested reasoning level (optional, capped by template max)
  ReasoningLevel reasoning_level = 13;

  // Override to disable Anthropic prompt caching for this request
  bool disable_input_token_cache = 14;

  // Optional prompt variables passed by the client for template rendering
  // Used by capability templates' system_prompt_append when variables use
  // request_key source Server applies automatic sanitization:
  // - Max 8KB per value, 64KB total
  // - Control characters stripped (except \n and \t)
  // - Values are treated as untrusted user input
  map<string, string> prompt_variables = 15;

  // Resume configuration for editing conversation history
  // When set, resumes conversation from a specific turn
  // Requires conversation_name to be set
  // Incompatible with direct messages array
  ResumeConfig resume_config = 16;

  reserved 3, 10, 11;
}

// Server → Client messages
message CreateResponseResult {
  oneof event {
    ResponseStarted response_started = 1;

    ContentDelta content_delta = 2;

    ContentDone content_done = 3;

    ThinkingDelta thinking_delta = 4;

    ThinkingDone thinking_done = 5;

    ToolCalls tool_calls = 6;

    ResponseComplete response_complete = 7;

    Error error = 8;

    CitationDelta citation_delta = 9;
  }
}

message ResponseStarted {
  string conversation_name = 1;

  string model_used = 2;

  repeated ToolInfo available_tools = 3;

  ModelCapabilities capabilities = 4;
}

message ContentDelta { string text = 1; }

message ContentDone { string text = 1; }

message ThinkingDelta { string text = 1; }

message ThinkingDone {
  string text = 1;

  string signature =
      2; // Opaque signature for thinking verification (Anthropic)
}

message CitationDelta {
  // Citation from common.proto
  Citation citation = 1;
}

message ResponseComplete {
  bool requires_tool_results = 1;

  StopReason stop_reason = 2;

  TokenUsage usage = 3; // Token usage for the current turn/request

  // Cumulative usage across entire conversation (aggregates all turns)
  // Only set for conversation requests, not set for non-conversation requests
  TokenUsage cumulative_usage = 4;
}

message Error {
  string code = 1;

  string message = 2;

  // Connector authentication errors that blocked this request
  // for the current user. Empty for non-connector-related failures.
  repeated ConnectorAuthError connector_auth_errors = 3;
}

// Client → Server messages for ChatStream
message ChatStreamRequest {
  oneof payload {
    InitializeSession init = 1;

    ChatInput input = 2;
  }
}

// Heavy initialization message - sent once at session start
message InitializeSession {
  // Model selection
  string model = 1;

  // Required capability template for ChatStream (connectors not supported here)
  string capability_template = 2;

  // Optional: Client declared tools
  repeated ToolDefinition client_tools = 3;

  // Default generation parameters
  GenerationParameters parameters = 4;

  // Default prompt variables for template rendering
  map<string, string> prompt_variables = 5;

  // Optional: bind to existing conversation (stateful mode)
  string conversation_name = 6;

  // Scope for authorization and tracking. Can be project, organization, or
  // empty.
  string parent = 7;
}

// Full-transcript input per turn with optional overrides
message ChatInput {
  repeated Message messages =
      1; // stateless: full transcript; stateful: delta-only

  InputOverrides overrides = 2; // optional

  // Stateful only: resume/edit operation. Incompatible with messages.
  ResumeConfig resume = 3;
}

// Per-input overrides grouped for clarity
message InputOverrides {
  GenerationParameters parameters = 1; // per-input generation params

  repeated ToolDefinition client_tools = 2; // authoritative when set

  map<string, string> prompt_variables = 3; // authoritative when set

  string model = 4;
}

// Grouped generation parameters
message GenerationParameters {
  int32 max_tokens = 1;

  float temperature = 2;

  ReasoningLevel reasoning_level = 3;

  google.protobuf.BoolValue disable_input_token_cache = 4;
}

// Server → Client messages for ChatStream
message ChatStreamResponse {
  oneof event {
    // Session initialization complete
    SessionInitialized session_initialized = 1;

    // Reuse all existing event types from CreateResponseResult
    ResponseStarted response_started = 2;

    ContentDelta content_delta = 3;

    ContentDone content_done = 4;

    ThinkingDelta thinking_delta = 5;

    ThinkingDone thinking_done = 6;

    ToolCalls tool_calls = 7;

    ResponseComplete response_complete = 8;

    Error error = 9;

    CitationDelta citation_delta = 10;
  }
}

// Session initialization confirmation
message SessionInitialized {
  // Conversation name (created or resumed)
  string conversation_name = 1;

  // Model that will be used for this session
  string model_used = 2;

  // Model capabilities
  ModelCapabilities capabilities = 3;
}
