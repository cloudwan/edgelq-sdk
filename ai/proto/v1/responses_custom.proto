syntax = "proto3";

package ntt.ai.v1;

import "edgelq-sdk/ai/proto/v1/common.proto";
import "google/protobuf/duration.proto";

option go_package = "github.com/cloudwan/edgelq-sdk/ai/client/v1/responses;responses_client";
option java_multiple_files = false;
option java_outer_classname = "ResponsesCustomProto";
option java_package = "com.ntt.ai.pb.v1";

// Client → Server messages
message CreateResponseRequest { CreateRequest create_request = 1; }

message CreateRequest {
  // The conversation
  repeated Message messages = 1;

  // Model selection
  string model = 2;

  // Client explicitly declares its tools
  repeated ToolDefinition client_tools = 4;

  // Server-side tool configuration - choose one:
  oneof server_tools_config {
    // Option 1: Use a pre-configured capability template
    string capability_template = 5;

    // Option 2: Directly specify connectors
    ConnectorsList connectors = 6;
  }

  // Standard LLM params
  int32 max_tokens = 7;

  float temperature = 8;

  // Optional: reference to existing conversation
  string conversation_name = 9;

  // Scope for authorization and tracking. Can be project, organization, or
  // empty. Format: "projects/{project}", "organizations/{org}", or ""
  string parent = 12;

  // Requested reasoning level (optional, capped by template max)
  ReasoningLevel reasoning_level = 13;

  // Override to disable Anthropic prompt caching for this request
  bool disable_input_token_cache = 14;

  reserved 3, 10, 11;
}

// Server → Client messages
message CreateResponseResult {
  oneof event {
    ResponseStarted response_started = 1;

    ContentDelta content_delta = 2;

    ContentDone content_done = 3;

    ThinkingDelta thinking_delta = 4;

    ThinkingDone thinking_done = 5;

    ToolCalls tool_calls = 6;

    ResponseComplete response_complete = 7;

    Error error = 8;

    CitationDelta citation_delta = 9;
  }
}

message ResponseStarted {
  string conversation_name = 1;

  string model_used = 2;

  repeated ToolInfo available_tools = 3;

  ModelCapabilities capabilities = 4;
}

message ToolInfo {
  string name = 1; // Tool name as sent to LLM

  // Tool source information
  oneof source {
    ClientToolSource client = 2;

    ConnectorToolSource connector = 3;

    InternalToolSource internal = 4;
  }
}

message ModelCapabilities {
  int32 context_window = 1;

  int32 max_output_tokens = 2;

  bool supports_tools = 3;

  bool supports_thinking = 4;

  repeated string supported_modalities = 5; // ["text", "image", "audio"]
}

message ContentDelta { string text = 1; }

message ContentDone { string text = 1; }

message ThinkingDelta { string text = 1; }

message ThinkingDone {
  string text = 1;

  string signature =
      2; // Opaque signature for thinking verification (Anthropic)
}

message CitationDelta {
  // Citation from common.proto
  Citation citation = 1;
}

message ResponseComplete {
  bool requires_tool_results = 1;

  StopReason stop_reason = 2;

  TokenUsage usage = 3; // Token usage for the current turn/request

  // Cumulative usage across entire conversation (aggregates all turns)
  // Only set for conversation requests, not set for non-conversation requests
  TokenUsage cumulative_usage = 4;
}

message Error {
  string code = 1;

  string message = 2;
}
