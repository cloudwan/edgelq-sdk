syntax = "proto3";

package ntt.ai.v1;

import "google/api/resource.proto";
import "google/type/money.proto";
import "goten-sdk/types/meta.proto";

option go_package = "github.com/cloudwan/edgelq-sdk/ai/resources/v1/chat_model;chat_model";
option java_multiple_files = true;
option java_outer_classname = "ChatModelProto";
option java_package = "com.ntt.ai.pb.v1";

// ChatModel Resource represents deployment of an AI chat model.
message ChatModel {
  option (google.api.resource) = {
    type : "ai.edgelq.com/ChatModel"
    pattern : "chatModels/{chat_model}"
    pattern : "projects/{project}/chatModels/{chat_model}"
  };

  // Name of ChatModel
  // When creating a new instance, this field is optional and if not provided,
  // it will be generated automatically. Last ID segment must conform to the
  // following regex: [a-z][a-z0-9\\-]{0,28}[a-z0-9]
  string name = 1;

  // Metadata is an object with information like create, update and delete time
  // (for async deleted resources), has user labels/annotations, sharding
  // information, multi-region syncing information and may have non-schema
  // owners (useful for taking ownership of resources belonging to lower level
  // services by higher ones).
  goten.types.Meta metadata = 2;

  oneof provider {
    AzureOpenAi azure_open_ai = 4;

    OpenAICompatible openai_compatible = 5;

    Anthropic anthropic = 6;

    Gemini gemini = 7;
  }

  // Human-readable display name
  string display_name = 8;

  // Optional cost metadata (pricing per 1M tokens).
  Cost cost = 9;

  message OpenAICompatible {
    string api_key = 1;

    // Model name or Azure deployment name
    string model = 2;

    // Optional: Custom endpoint for compatible APIs
    string base_url = 3;

    // Optional: OpenAI organization ID
    string organization = 4;

    // Optional: Azure-specific endpoint (e.g.,
    // https://myresource.openai.azure.com)
    string azure_endpoint = 5;

    // Optional: Azure API version (e.g., "2024-06-01")
    string azure_api_version = 6;

    // Maximum output tokens
    int32 max_output_tokens = 7;
  }

  message Anthropic {
    string api_key = 1;

    // Model name (e.g., "claude-3-opus", "claude-3-sonnet")
    string model = 2;

    // Optional: Custom endpoint
    string base_url = 3;

    // Maximum output tokens (must be >= 4096 for Anthropic)
    int32 max_output_tokens = 4;
  }

  message Gemini {
    string api_key = 1;

    // Model name (e.g., "gemini-pro", "gemini-ultra")
    string model = 2;

    // Maximum output tokens
    int32 max_output_tokens = 3;
  }

  message AzureOpenAi {
    // Azure OpenAI endpoint (e.g., https://myresource.openai.azure.com)
    string endpoint = 1;

    // Azure API key
    string api_key = 2;

    // Azure deployment name
    string deployment_name = 3;

    // API version (e.g., "2024-10-21")
    string api_version = 4;

    // Maximum output tokens
    int32 max_output_tokens = 5;
  }

  // Cost captures pricing per 1M tokens for each billing bucket.
  message Cost {
    // Cost for uncached input tokens per 1M tokens.
    google.type.Money input_per_million = 1;

    // Cost for cached input tokens per 1M tokens (discounted rate).
    google.type.Money cached_input_per_million = 2;

    // Cost for cache writes with a 5 minute TTL per 1M tokens.
    google.type.Money cache_write_five_min_per_million = 3;

    // Cost for cache writes with a 1 hour TTL per 1M tokens.
    google.type.Money cache_write_one_hour_per_million = 4;

    // Cost for output tokens per 1M tokens.
    google.type.Money output_per_million = 5;
  }

  reserved 3;
}
