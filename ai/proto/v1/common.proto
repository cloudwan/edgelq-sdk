syntax = "proto3";

package ntt.ai.v1;

import "google/protobuf/duration.proto";
import "google/protobuf/timestamp.proto";

option go_package = "github.com/cloudwan/edgelq-sdk/ai/client/v1/common;common_client";
option java_multiple_files = false;
option java_outer_classname = "CommonProto";
option java_package = "com.ntt.ai.pb.v1";

// Message structure for conversations
message Message {
  string role = 1; // "user", "assistant", "system", "tool"

  repeated ContentPart parts = 2;
}

// Multimodal content part
message ContentPart {
  oneof content {
    TextContent text = 1;

    ImageContent image = 2;

    AudioContent audio = 3;

    FileContent file = 4;

    ToolCallContent tool_call = 5;

    ToolResultContent tool_result = 6;

    ThinkingContent thinking = 7;
  }
}

message TextContent { string text = 1; }

message ImageContent {
  oneof source {
    string url = 1;

    bytes data = 2;
  }

  string mime_type = 3;
}

message AudioContent {
  oneof source {
    string url = 1;

    bytes data = 2;
  }

  string mime_type = 3;
}

message FileContent {
  string name = 1;

  string mime_type = 2;

  oneof source {
    string url = 3;

    bytes data = 4;
  }
}

message ToolCallContent {
  string id = 1;

  string name = 2;

  string input = 3; // JSON arguments
}

message ToolResultContent {
  string tool_call_id = 1;

  oneof result {
    string content = 2; // JSON result

    string error = 3;
  }
}

// Thinking/reasoning content with optional signature
message ThinkingContent {
  string text = 1; // Thinking/reasoning text

  string signature =
      2; // Opaque signature for verification (Anthropic only, empty for others)
}

// Token usage information
message TokenUsage {
  int32 input_tokens = 1;

  int32 output_tokens = 2;

  int32 total_tokens = 3;

  InputTokenDetails input_details = 4;

  OutputTokenDetails output_details = 5;

  TokenUsageMetadata metadata = 6;
}

// Metadata about the request (provider, model, service tier)
message TokenUsageMetadata {
  string provider =
      1; // "openai" | "anthropic" | "gemini" | "xai" | "azure-openai"

  string model = 2; // e.g. "gpt-4o-2024-08-06", "claude-3-5-sonnet-20241022"

  string service_tier = 3; // OpenAI: "scale" | "default" (if applicable)
}

// Input/prompt token breakdown
message InputTokenDetails {
  // Generic fields (all providers)
  int32 cached_tokens = 1; // Cache reads (all providers map here)

  int32 cache_write_tokens =
      2; // Cache writes (Anthropic today, others in future)

  int32 audio_tokens = 3; // Audio input tokens

  // Provider-specific details (for advanced use cases)
  oneof provider {
    AnthropicCacheTokens anthropic = 10;

    GeminiInputTokens gemini = 11;
  }
}

// Output/completion token breakdown
message OutputTokenDetails {
  // Generic fields (all providers)
  int32 reasoning_tokens = 1; // OpenAI o1, Gemini thinking, DeepSeek R1

  int32 audio_tokens = 2; // Audio output tokens

  // Provider-specific details
  oneof provider {
    OpenAIPredictionTokens openai = 10;

    GeminiOutputTokens gemini = 11;
  }
}

// OpenAI predicted outputs (latency optimization feature)
message OpenAIPredictionTokens {
  int32 accepted_prediction_tokens = 1;

  int32 rejected_prediction_tokens = 2;

  bool predicted_outputs_used = 3;
}

// Anthropic cache token details (with TTL-based pricing tiers)
message AnthropicCacheTokens {
  // Total cache writes (same as generic cache_write_tokens)
  int32 cache_creation_input_tokens = 1;

  // TTL breakdown (5min=1.25x, 1hour=2x pricing)
  CacheCreationByTTL cache_creation = 2;
}

// Anthropic cache creation by TTL (for billing differentiation)
message CacheCreationByTTL {
  int32 ephemeral_5m_input_tokens = 1; // 1.25x base rate

  int32 ephemeral_1h_input_tokens = 2; // 2.0x base rate
}

// Gemini input token details (tool use & multimodal breakdown)
message GeminiInputTokens {
  // Tool execution results fed back to model
  int32 tool_use_prompt_token_count = 1;

  // Multimodal breakdowns
  repeated ModalityTokenCount prompt_tokens_details = 2;

  repeated ModalityTokenCount cache_tokens_details = 3;

  repeated ModalityTokenCount tool_use_prompt_tokens_details = 4;
}

// Gemini output token details (multimodal breakdown)
message GeminiOutputTokens {
  repeated ModalityTokenCount candidates_tokens_details = 1;
}

// Per-modality token count (Gemini)
message ModalityTokenCount {
  string modality = 1; // "TEXT" | "IMAGE" | "VIDEO" | "AUDIO"

  int32 token_count = 2;
}

// Payload for data with media type
message Payload {
  oneof body {
    string json = 1;

    bytes data = 2;
  }

  string media_type = 3;
}

// Tool definition
message ToolDefinition {
  string name = 1;

  string description = 2;

  string input_schema = 3; // JSON Schema

  string provider = 4; // Provider reference (optional)
}

// Tool call for execution
message ToolCall {
  string id = 1;

  string name = 2;

  string arguments = 3; // JSON arguments
}

// Tool response
message ToolResponse {
  string tool_call_id = 1;

  string tool = 2;

  oneof result {
    Payload output = 3;

    string error = 4;
  }
}

// Tool calls container
message ToolCalls { repeated ToolCall calls = 1; }

// Citation - reference to source material (provider-agnostic)
message Citation {
  // Text reference in AI response (which part is cited)
  int64 start_index = 1; // Character position in AI message

  int64 end_index = 2; // Character position in AI message

  string text = 3; // Text in AI response being cited

  // Source information
  CitationSource source = 4;
}

// Citation source information
message CitationSource {
  // Core fields (all providers)
  string title = 1; // Document/page/website title

  string id = 2; // Opaque identifier (file_id, chunk_id, url, etc.)

  string quoted_text = 3; // Actual text from source document

  // Location in source (flexible for all provider types)
  oneof location {
    CharacterRange char_range = 4;

    PageReference page = 5;

    URLReference url = 6;
  }

  // Generic metadata (extensible for any provider-specific data)
  map<string, string> metadata = 10;
}

// Character range in source document
message CharacterRange {
  int64 start = 1;

  int64 end = 2;
}

// Page reference in source document
message PageReference { int32 page_number = 1; }

// URL reference
message URLReference {
  string url = 1;

  string filepath = 2; // Optional: for file-based URLs
}

// Content channel type
enum ContentChannel {
  CONTENT_CHANNEL_UNSPECIFIED = 0;

  CONTENT_CHANNEL_CONTENT = 1; // Visible assistant response

  CONTENT_CHANNEL_THINKING = 2; // Internal reasoning
}

// LLM/Provider specific errors
enum LLMError {
  LLM_ERROR_UNSPECIFIED = 0;

  LLM_RATE_LIMIT = 1; // Provider rate limiting

  LLM_CONTENT_FILTER = 2; // Content filtered by provider

  LLM_PROVIDER_ERROR = 3; // General provider failure

  LLM_TOOL_ERROR = 4; // Tool execution failed
}

// Reasoning/thinking level for AI models
enum ReasoningLevel {
  REASONING_LEVEL_DEFAULT = 0; // Use model's default

  REASONING_LEVEL_LOW = 1; // Fast/minimal reasoning

  REASONING_LEVEL_MEDIUM = 2; // Balanced reasoning

  REASONING_LEVEL_HIGH = 3; // Deeper reasoning
}
