syntax = "proto3";

package ntt.ai.v1;

import "google/protobuf/duration.proto";
import "google/protobuf/timestamp.proto";
import "google/type/money.proto";

option go_package = "github.com/cloudwan/edgelq-sdk/ai/client/v1/common;common_client";
option java_multiple_files = false;
option java_outer_classname = "CommonProto";
option java_package = "com.ntt.ai.pb.v1";

// Message structure for conversations
message Message {
  string role = 1; // "user", "assistant", "system", "tool"

  repeated ContentPart parts = 2;
}

// Multimodal content part
message ContentPart {
  oneof content {
    TextContent text = 1;

    ImageContent image = 2;

    AudioContent audio = 3;

    FileContent file = 4;

    ToolCall tool_call = 5;

    ToolResponse tool_result = 6;

    ThinkingContent thinking = 7;
  }
}

message TextContent { string text = 1; }

message ImageContent {
  oneof source {
    string url = 1;

    bytes data = 2;
  }

  string mime_type = 3;
}

message AudioContent {
  oneof source {
    string url = 1;

    bytes data = 2;
  }

  string mime_type = 3;
}

message FileContent {
  string name = 1;

  string mime_type = 2;

  oneof source {
    string url = 3;

    bytes data = 4;
  }
}

// Thinking/reasoning content with optional signature
message ThinkingContent {
  string text = 1; // Thinking/reasoning text

  string signature =
      2; // Opaque signature for verification (Anthropic only, empty for others)
}

// Token usage information
message TokenUsage {
  // === TOKEN TOTALS ===
  int32 input_tokens = 1; // Total: fresh + cached + cache_writes

  int32 output_tokens = 2; // Total: regular + reasoning + audio

  int32 total_tokens = 3; // input_tokens + output_tokens

  // === UNIVERSAL BREAKDOWNS (all providers map here) ===
  InputTokenBreakdown input_breakdown = 13;

  OutputTokenBreakdown output_breakdown = 14;

  TokenUsageMetadata metadata = 6;

  // === COST BREAKDOWN (1:1 mapping to breakdown categories) ===
  // Costs are zero when pricing is unknown.
  google.type.Money input_cost = 7; // Cost for fresh_input tokens

  google.type.Money cached_input_cost = 8; // Cost for cached_input tokens

  google.type.Money cache_write_five_min_cost =
      9; // Cost for cache_write_five_min tokens

  google.type.Money cache_write_one_hour_cost =
      10; // Cost for cache_write_one_hour tokens

  google.type.Money output_cost = 11; // Cost for output tokens (all types)

  google.type.Money total_cost = 12; // Sum of all costs
}

// Universal input token breakdown (all providers map here)
message InputTokenBreakdown {
  int32 fresh_input = 1; // New input tokens processed (not from cache)

  int32 cached_input = 2; // Input tokens served from cache (cache hits)

  int32 cache_write_five_min = 3; // Tokens written to cache with 5-minute TTL

  int32 cache_write_one_hour = 4; // Tokens written to cache with 1-hour TTL

  int32 audio_input = 5; // Audio input tokens (OpenAI, Azure)

  int32 tool_use_input = 6; // Tool execution results fed back to model (Gemini)
}

// Universal output token breakdown (all providers map here)
message OutputTokenBreakdown {
  int32 regular_output = 1; // Regular completion tokens

  int32 reasoning_output =
      2; // Reasoning/thinking tokens (o1, Gemini thinking, DeepSeek-R1, etc.)

  int32 audio_output = 3; // Audio output tokens
}

// Metadata about the request (provider, model, service tier)
message TokenUsageMetadata {
  string provider =
      1; // "openai" | "anthropic" | "gemini" | "xai" | "azure-openai"

  string model = 2; // e.g. "gpt-4o-2024-08-06", "claude-3-5-sonnet-20241022"

  string service_tier = 3; // OpenAI: "scale" | "default" (if applicable)
}

// Payload for data with media type
message Payload {
  oneof body {
    string json = 1;

    bytes data = 2;
  }

  string media_type = 3;
}

// Tool definition
message ToolDefinition {
  string name = 1;

  string description = 2;

  string input_schema = 3; // JSON Schema

  string provider = 4; // Provider reference (optional)
}

// Tool call for execution
message ToolCall {
  string id = 1;

  string name = 2;

  string arguments = 3; // JSON arguments
}

// Tool response
message ToolResponse {
  string tool_call_id = 1;

  string tool = 2;

  oneof result {
    Payload output = 3;

    string error = 4;
  }
}

// Tool calls container
message ToolCalls { repeated ToolCall calls = 1; }

// Tool source types (shared across chat and conversation persistence)
// Client tool - executed by client locally
message ClientToolSource {}

// Connector tool - executed via MCP/other connector
message ConnectorToolSource { string connector_name = 1; }

// Internal server tool (e.g., RAG)
message InternalToolSource {
  Type type = 1;

  // Capability Template name for internal tools
  // Server knows how to extract the right config from the template
  string template_name = 2;

  enum Type {
    TYPE_UNSPECIFIED = 0;

    RAG = 1;
  }
}

// Citation - reference to source material (provider-agnostic)
message Citation {
  // Text reference in AI response (which part is cited)
  int64 start_index = 1; // Character position in AI message

  int64 end_index = 2; // Character position in AI message

  string text = 3; // Text in AI response being cited

  // Source information
  CitationSource source = 4;
}

// Citation source information
message CitationSource {
  // Core fields (all providers)
  string title = 1; // Document/page/website title

  string id = 2; // Opaque identifier (file_id, chunk_id, url, etc.)

  string quoted_text = 3; // Actual text from source document

  // Location in source (flexible for all provider types)
  oneof location {
    CharacterRange char_range = 4;

    PageReference page = 5;

    URLReference url = 6;
  }

  // Generic metadata (extensible for any provider-specific data)
  map<string, string> metadata = 10;
}

// Character range in source document
message CharacterRange {
  int64 start = 1;

  int64 end = 2;
}

// Page reference in source document
message PageReference { int32 page_number = 1; }

// URL reference
message URLReference {
  string url = 1;

  string filepath = 2; // Optional: for file-based URLs
}

// Per-connector auth failure for the current user in a single API call.
message ConnectorAuthError {
  // Full connector resource name, e.g. "connectors/projects/.../connectorId"
  string connector = 1;

  ConnectorAuthErrorCode code = 2;
}

// List of connectors for direct specification
message ConnectorsList { repeated string connector = 1; }

// Tool information including source
message ToolInfo {
  string name = 1; // Tool name as sent to LLM

  // Tool source information
  oneof source {
    ClientToolSource client = 2;

    ConnectorToolSource connector = 3;

    InternalToolSource internal = 4;
  }
}

// Model capabilities information
message ModelCapabilities {
  int32 context_window = 1;

  int32 max_output_tokens = 2;

  bool supports_tools = 3;

  bool supports_thinking = 4;

  repeated string supported_modalities = 5; // ["text", "image", "audio"]
}

// Resume configuration for editing conversation history
message ResumeConfig {
  // Resume conversation from this turn (0-indexed)
  // The turn at from_turn and all turns after will be moved to
  // replaced_turn_groups
  int32 from_turn = 1;

  // Optional: Replacement message for this turn
  // Can be role="user" or role="tool" depending on turn type
  // If not set, uses the original message from that turn
  // Must match the role of the first message in the original turn
  Message replace_message = 2;

  // Optional: User comment/reason for the resume operation
  // Will be stored in ReplacedTurnGroup.resume_reason
  string resume_reason = 3;

  // Explicit enable flag to avoid ambiguity when clients send an empty struct
  // If false or unset, server must treat this as not a resume request
  bool resume_enabled = 4;
}

// Content channel type
enum ContentChannel {
  CONTENT_CHANNEL_UNSPECIFIED = 0;

  CONTENT_CHANNEL_CONTENT = 1; // Visible assistant response

  CONTENT_CHANNEL_THINKING = 2; // Internal reasoning
}

// LLM/Provider specific errors
enum LLMError {
  LLM_ERROR_UNSPECIFIED = 0;

  LLM_RATE_LIMIT = 1; // Provider rate limiting

  LLM_CONTENT_FILTER = 2; // Content filtered by provider

  LLM_PROVIDER_ERROR = 3; // General provider failure

  LLM_TOOL_ERROR = 4; // Tool execution failed
}

// Reasoning/thinking level for AI models
enum ReasoningLevel {
  REASONING_LEVEL_DEFAULT = 0; // Use model's default

  REASONING_LEVEL_LOW = 1; // Fast/minimal reasoning

  REASONING_LEVEL_MEDIUM = 2; // Balanced reasoning

  REASONING_LEVEL_HIGH = 3; // Deeper reasoning
}

// Stop reason for response generation
enum StopReason {
  STOP_REASON_UNSPECIFIED = 0;

  STOP_REASON_COMPLETED = 1; // Natural completion

  STOP_REASON_MAX_TOKENS = 2; // Hit token limit

  STOP_REASON_TOOL_CALLS = 3; // Stopped to execute tools

  STOP_REASON_ERROR = 4; // Error occurred

  STOP_REASON_CONTENT_FILTER = 5; // Content filtered
}

// ConnectorAuthErrorCode describes why connector OAuth auth failed
// for the current user in the context of a single API call.
enum ConnectorAuthErrorCode {
  CONNECTOR_AUTH_ERROR_CODE_UNSPECIFIED = 0;

  // No connector OAuth token is available for this user.
  CONNECTOR_AUTH_ERROR_CODE_REQUIRED = 1;

  // Token exists but is expired and cannot be automatically refreshed.
  CONNECTOR_AUTH_ERROR_CODE_EXPIRED = 2;

  // Refresh attempt failed (e.g. provider returned invalid_grant/401).
  CONNECTOR_AUTH_ERROR_CODE_REFRESH_FAILED = 3;

  // Connector token exists and is still valid, but the provider requires an
  // additional consent flow (e.g. downstream resource scopes) before it can
  // be used successfully.
  CONNECTOR_AUTH_ERROR_CODE_DOWNSTREAM_CONSENT_REQUIRED = 4;
}
